### 以太网头
以太网格式帧：
![mac frame](http://akaedu.github.io/book/images/tcpip.ethernetformat.png)

7字节的前导码用来做同步，典型值为0xAA，0101的序列。SFD为帧的起始定界符，固定值为0xAB。
目的MAC地址和源MAC地址，都是6字节，以外网帧的目的地址允许寻址到多个站点（广播和组播）。
2字节类型，表示数据区payload的协议，常见值为0x0800（IPv4），0x0806（ARP，IP->MAC）。
4字节检验和，用于差错传输，使用CRC冗余校验检查包是否有效。

payload最大值1500称为以太网的最大传输单元MTU。不同网络类型有不同的MTU，如果链路传输大于MTU，需要对数据包进行分片。

### ARP数据报
![arp header](http://akaedu.github.io/book/images/tcpip.arpformat.png "arp header")

ARP请求数据报的以太网目的地址会填入ff:ff:ff:ff:ff:ff。

源MAC地址、目的MAC地址在以太网首部和ARP请求中各出现一次，对于链路层为以太网的情况是多余的，但如果链路层是其它类型的网络则有可能是必要的。

### IP头
![ip header](http://xiazi97.github.io/2019/01/28/IP%E5%8D%8F%E8%AE%AE/%E6%8A%A5%E5%A4%B4.png)
IP数据报首部长度和数据长度都是可变的，但总是4字节整数倍。首部至少是20字节，最大15×4=60字节。
TOS用3位指定IP数据报优先级（弃用），用另外4位表示服务类型（最小延迟、最大吞吐、可靠性、成本）。
总长度以四字节为单位，它表示首部和payload的总长度。
每传一个IP数据报，16位标识加1，用于数据报分片和重组。
3位标志和13位分片偏移，用于分片。
8位TTL表示数据报生命周期，每经过一个路由器（hop），该值减1。
8位协议字段标识上层协议，可能是TCP、UDP、ICMP、IGMP。
16位检验和，只检验IP首部，数据的校验由更高层协议完成。

* IP分片
IP头使用3位标志和13位片偏移来支持IP分片和重组。标志位中第0位强制为0，第一位DF表示不分片，第2位MF表示更多分片（中间分片为1，最后一个分片为0）。同一个分片的2字节标识是相同的。

* 避免IP分片
IP层没有超时重传机制，如果其中一个分片丢失了，只能依赖传输层将所有分片重传一次，代价大。

### UDP头
![udp header](http://c.biancheng.net/uploads/allimg/191111/6-1911111249535K.gif)

UDP至少包含8字节头，分别是2字节源端口，2字节目的端口，2字节长度，表示udp头+数据的长度，数据可以为空，所以长度值最小为8Byte，校验和对udp头+数据作CRC校验，保证传输过程中数据不会损坏。

### TCP头
![tcp header](https://images.cnblogs.com/cnblogs_com/shenpengyan/887877/o_tcp%E5%A4%B4%E9%83%A82.jpg)

TCP至少包含20字节。分别是2字节的源端口，2字节目的端口，4字节序列号，4字节应答号，4位的头部长度指示数据从何处开始，4位保留，8位标志位，2字节接收窗口，用来表示接收窗口还剩多大，2字节校验和，CRC校验了头部和数据，用于指示数据在传输过程中是否损坏，16位紧急指针代表一个偏移，用来发送紧急数据的方法。TCP选项部分最多包含40字节。TCP最长为60字节。

当紧急指针标志位URG置位时，紧急指针才生效，它指向的区域之后的数据是正常数据，之前的所有数据是紧急数据，也称为带外数据（out-of-band，OOB）。
紧急数据被接收时，立即触发SIGURG信号，在信号处理函数中使用MSG_OOB标志recv就可以获取带外数据。

### ICMP头
![imcp header](http://img-blog.csdn.net/20170513005317177 "imcp header")

ICMP（Internet Control Message Protocol）因特网控制报文协议。它是IPv4协议族中的一个子协议，用于IP主机、路由器之间传递控制消息。控制消息是在网络通不通、主机是否可达、路由是否可用等网络本身的消息。

ICMP头前20字节是IP头，ICMP报文头至少8字节，分别是8位的类型码，标识ICMP报文类型，可能代表超时，无法到达目标等等，8位代码，它和类型字段一起公共表示ICMP报文的详细类型，比如无法到达可能分为不能访问主机、无法访问协议、无法访问端口等。
2字节校验和，校验头和数据的CRC，以检验报文传输过程中是否发生差错，2字节标识符，仅用于回显请求和应答ICMP报文（序列号：对应多次ping）。

ICMP报文分为两种：询问报文和ICMP差错报告报文；根据报文类型不同，可能没有标识符和序列号字段。

差错报告报文：目的地不可到达，超时，参数错，重定向等；
询问报文：ECHO请求，时间戳同步请求等；

### ping协议
ping程序是用来探测主机到主机之间是否可通信。
如果不能ping到某台主机，表明不能和这台主机建立连接。ping使用ICMP协议，它发送ICMP回送ECHO请求消息给目的主机。ICMP协议规定：目的主机必须返回ICMP回送应答消息给源主机。如果源主机在一定时间内收到应答，则认为主机可达。

ICMP协议通过IP协议发送的，IP协议是一种无连接的，不可靠的数据包协议。在Unix/Linux，序列号从0开始计数，依次递增。而Windows ping程序的ICMP序列号是没有规律。

ICMP协议在实际传输中数据包：20字节IP首部 + (8字节ICMP首部+ 1472字节<数据大小>) 28字节
ICMP报文格式:IP首部(20字节)+8位类型+8位代码+16位校验和+(不同的类型和代码，格式也有所不同)

### traceroute协议
traceroute是用来侦测主机到目的主机之间所经路由情况。

traceroute操作IP头TTL字段，从1开始递增。这使得从源IP到目的IP的每一跳，都触发一次超时。
这些超时请求，路由器会回一个ICMP包，告诉源IP，这个包已被丢弃。
所以，traceroute可以获取从源IP到目的IP经过的所有路由器。

为了降低开销，traceroute使用UDP协议。
在探测路由路径时，traceroute会使用一个随机，且较大的端口。让这个UDP包到达目的主机时，由于端口未被使用，也返回一个端口不可到达的ICMP包。

### HTTP协议
* HTTP1.0
    * 使用keep-alive参数来告知服务器端要建立一个长连接
    * 发送请求时将body都带上，不支持断点续传

* HTTP1.1
    * 缓存处理
        * 引入更多的缓存头控制缓存策略
    * 支持断点续传
        * Header指定range字段，表示请求字节区间
        * 回包指定content-range，表示body字节区间
    * 默认长连接
        * HTTP基于TCP/IP，有三次握手、四次挥手的开销，最好复用连接
    * 支持HOST域
        * 同一个IP可对应多个虚拟主机，即一台物理机可以有多个逻辑主机
    * 支持Pipeline
        * 允许同一个连接发多个HTTP请求，一定程度上缓解队头阻塞问题

* HTTP2.0
    * 支持多路复用
        * 一个TCP连接承接多个双向流通的HTTP流，每个流有唯一的标识和优先级，接受端根据优先级进行组装。
    * 支持Header HPACK压缩算法
        * 维护一个静态字典和动态字典，发送请求时，使用字典索引，而不是完整字符串
        * 静态字典包含常见头部名称与值，对于字典中不包含的内存荣，使用哈夫曼编码减小体积
    * 支持server push服务器推送
        * 允许服务器给浏览器推送资源
        * 主要根据请求页面，预测主请求所依赖的资源，并直接推送给浏览器

* HTTP3.0
    * Google QUIC协议，使用udp实现
    * 主要解决HTTP2.0复用同一个连接时，但其中一个数据流包丢失，TCP会等待它，造成阻塞。
    * 虽然HTTP知道包是逻辑独立的，但是TCP不感知，它只知道接受窗口空了一段，因此阻塞住，等待回传。这时候不会将数据上报给应用层，滑动窗口也不会移动。
    * QUIC使用UDP，各个消息是独立的，不存在TCP这种队头阻塞。

### IO模型
* 阻塞IO
可能因为阻塞而被挂起。阻塞期间可能被打断而返回错误，errno设置为EINTR。

![block io](http://upload-images.jianshu.io/upload_images/9795603-c585737e23f3ca21.png)

* 非阻塞IO
陷入内核没有数据，或者操作失败直接返回。

![non-block io](http://upload-images.jianshu.io/upload_images/9795603-35c4a25b6e395081.png)

* IO多路复用
会阻塞在select、poll和epoll。

![multiplex](https://upload-images.jianshu.io/upload_images/9795603-a896c412cf7e9707.png)

* SIGIO
通过SIGIO信号来通知I/O事件，但是SIGIO不会阻塞应用程序。需要在信号处理函数中，完成读写操作。

![sigio](http://upload-images.jianshu.io/upload_images/9795603-a0fe92736a8c146a.png)

* 异步IO
POSIX规范定义了一组异步操作IO的接口，不用关心fd是阻塞还是非阻塞，异步IO是由内核接管应用层对fd的IO操作。异步IO向应用层通知IO操作完成事件。真正做到非阻塞读写，所有读写由内核完成。

![async io](http://upload-images.jianshu.io/upload_images/9795603-70537c4ff58467a6.png)


### socket backlog
backlog规定了套接字排队的最大连接数。默认是128个。

一个监听套接字维护两个队列，
* 未完成连接队列，收到SYN包，并处于SYN_RECV状态，并等待ACK或者超时（默认75s）
* 已完成连接队列，完成三次握手，处于ESTABLISH状态，等待accept

设置为SOCKET_MAXBACKLOG，最大为1024个。

### 三次握手
客户端C请求连接报文，设置SYN标志位，并生成一个序列号seq=x；然后进入SYN_SEND状态；

服务器端S接收到带SYN的报文，也生成一个序列号seq=y，并设置SYN和ACK=x+1，传给C端；然后进入SYN_RECV状态；

C端收到带SYN+ACK的包，回一个ACK=y+1的应答；此时C端进入ESTABLISH状态；

S端收到应答，也进入ESTABLISH状态。

![three-way handshaking](http://images2015.cnblogs.com/blog/816045/201611/816045-20161105220355065-482198403.png)

* 为什么需要三次握手？
为实现可靠的数据传输，TCP协议通信双方，都必须维护一个序列号，标识发送的包中哪些是被对方确认的。所以三次握手过程是通知对方自己的初始序列号，并双方都确认了。

所以握手过程至少需要三个环节。两次通信，只能让其中一方确认序列号。

### 四次挥手
主机A主动断开连接，设置FIN标志位，ACK为主机B的序列号+1，发送给B；A进入FIN_WAIT_1状态；
主机B收到FIN报文，回一个ACK包；此时B进入CLOSE_WAIT状态；A收到ACK包，进入FIN_WAIT_2状态；

此时主机A到主机B方向连接断开；但主机B仍可以继续发送数据到A；

主机B发送一个FIN报文给A，请求关闭B到A方向上的连接；此时B进入LAST_ACK状态；A收到FIN报文，进入TIME_WAIT状态；
主机A发送一个ACK包确认，进入TIME_WAIT_2状态；主机B收到ACK包，进入close状态。

经过2MSL时间，主机A进入close状态。

* 为什么需要四次挥手？
TCP是全双工协议，双方都可以既发送也接收数据。所以断开连接时，也需要从两个方向关闭连接。

A向B发送一次FIN分节，关闭A到B方向的连接；此时A不允许在发送数据到B，但仍然可以接收数据；
最后，B向A发送一次FIN分节，关闭B到A方向的连接。

### time_wait状态
time_wait和time_wait2状态都出现在主动断开方。

time_wait状态出现在主动断开方收到对方的FIN分节，表示对方也要关闭此连接；
time_wait2状态出现在主动断开方发送FIN分节的ACK应答时，表示确认断开此连接。

* 为什么需要time_wait状态？
    * 可靠的实现TCP全双工连接的终止；（可靠的终止，最后一个ACK可能丢失）
    * 允许老的重复分节在网络中消逝。（重复分节处理）

假设主动断开方最后的ACK丢失，触发了对端重发FIN分节，此时如果不维护time_wait状态，对端将收到RST分节。这将被解释为错误。

另一个原因是，对端的重复分节可能在主动断开方发送最后一个ACK之后到来，如果没有time_wait2这个状态，那么对端也将收到RST。（网络质量会波动，有可能会有一些超时重发，网络中遗留一些重复分节。可能串会话了）

* 为什么出现大量的time_wait？
    * 一般而言，服务器不主动断开，但如果是smtp，ftp协议，收到客户端的quit命令，会主动断开。此时可能出现大量的time_wait状态；
    * 对于大并发，服务器连接数超限，将新连接都将被主动关闭，此时可能出现大量的time_wait；
    * 对于大量的不活跃连接同时清理，可能导致产生大量的time_wait状态。
    * HTTP1.0短连接方式的请求，每次请求接受后，服务端可能主动断开连接。

* 为什么出现大量的close_wait？
close_wait出现在被动断开方，一般是服务器内部错误导致没有正常释放连接。没有关闭socket。

close_wait在收到对方的FIN分节，但是自身还未发送FIN的状态；还可能的原因是服务器本身还在忙读，或者忙写，还没有来得及发送FIN。

### TCP与UDP
TCP是面向连接的提供可靠交付的全双工通信协议。UDP是一种无连接，无状态的，不可靠的数据传输协议。

UDP最大的优势是快。一次TCP通信最小有7次通信过程，三次握手和四次挥手，同时还有确认、滑动窗口、重传，流量控制、拥塞控制机制，这些机制保证TCP可靠交付，但也占用较高的系统资源，处理效率也低。而UDP没有这些限制，所以，UDP适合一些实时性要求高但通信质量不高的场景，如QQ语音，视频电话等。

但是TCP是一种有状态协议，更容易被攻击。如DOS，DDOS等，只发一个SYN握手报文，服务器维持了该连接状态，占用资源。当连接数过多，服务器资源耗尽，不能对外提供服务。

### OSI七层模型
物理层：负责0、1比特流(0/1序列)与电压的高低、光的闪灭之间的转换

数据链路层：负责物理层面上的互联的、节点间的通信传输。该层的作用包括物理地址寻址、数据的成帧、流量控制、数据的检错、重发等。在这一层，数据的单位称为帧(frame)。

网络层：将数据传输到目标地址。目标地址可以是多个网络通过路由器连接而成的某一个地址，主要负责寻找地址和路由选择，网络层还可以实现拥塞控制、网际互连等功能。这一层的数据单位称为数据包(packet)

传输层：传输层提供端的交换数据的机制，检查分组编号与次序，传输层对其上三层如会话层等，提供可靠的传输服务，对网络层提供可靠的目的地站点信息。这一层的数据单位称为数据段(segment)。

会话层：负责建立和断开通信连接（数据流动的逻辑通路），记忆数据的分隔等数据传输相关的管理。

表示层：将应用处理的信息转换为适合网络传输的格式，或将来自下一层的数据转换为上层能够处理的格式。

应用层：为应用程序提供服务并规定应用程序中通信相关的细节。

### TCP可靠性
* 连接管理，包括三次握手、四次挥手
* 序列号，ACK确认
* 超时重传
* 滑动窗口
* 拥塞控制
* 流量控制

序列号：初始握手环节，产生初始的序列号，并用序列号标识发送的字节数。SYN，FIN包会占一个序列号；
确认号：接收缓冲中最后一个非失序报文的下一个字节。


### TCP重传
接收端给发送端的ACK确认只会确认最后一个连续的包。
* 超时重传机制：发送方在计数器到期时收不到ACK，就重传这个包。
* 快速重传机制：发送方连续收到三次相同的ACK，就重传这个包。

Sack方法（selective ack）：使用快速重传的机制，但在TCP后加入SACK信息，用来标记最后一个确认包之后收到了那些断续的包。这样发送方解析该字段，只发送空缺的报文。（TCP选项字段）

### TCP滑动窗口
滑动窗口实现了TCP流量控制和乱序重排。

TCP是全双工协议，会话双方都维护一个发送窗口和一个接收窗口。接受窗口大小取决于系统、硬件的限制。发送窗口取决于对端通告的接收窗口。

![](http://codeantenna.com/image/https://img-blog.csdn.net/20130801215536296?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2ljb2ZpZWxk/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

发送方缓存分为：已发送并确认、已发送未确认、未发送但允许发送、未发送且不允许发送；
其中发送窗口为已发送未确认和未发送但允许发送。

接受缓存分为：已接收并交付、允许接受、不允许接受；
其中接受串口是允许接受。

接收窗口左边界报文被确认后，接收窗口才会右移。这保证了报文上报应用层时，不会乱序。
发送方不仅需要控制发送窗口，也要根据对方的接受窗口，控制发送的数据量。

zero window：一个处理缓慢的server遇到一个快速发送的client，可能出现发送窗口降为0。在这种情况，发送端不发送数据，会使用TCP Zero Window Probe（ZWP）技术，发送ZWP包给接收方，接收方来ACK他的接收窗口尺寸。

### TCP流量控制
TCP流量控制是借由滑动窗口实现。
接收方会ack它的接收窗口大小，发送方根据接收窗口大小调整发送数据量。

### TCP拥塞控制
拥塞控制：防止过多的数据注入网络中，这样可以使得网络中的路由器和链路不致过载。

拥塞控制的方法：慢开始、拥塞避免、快重传和快恢复。

慢开始与拥塞避免：当主机开始发送数据时，如果立即大量的数据注入到网络，那么很可能引起网络拥塞，因为不知道当前网络的负荷情况。较好的办法是先探测一下，发送窗口由小逐渐增大。

慢开始：开始时拥塞窗口设置为1，此后每经过一次传输轮次（一个RTT），拥塞窗口cwnd就加倍。为了防止拥塞窗口增长过大，引起网络拥塞，还需要设置一个慢开始门限ssthresh。当cwnd小于ssthresh时，采用慢开始算法；当cwnd大于ssthresh时，采用拥塞避免算法。

拥塞避免：让拥塞窗口cwnd缓慢增加，每个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这使得拥塞窗口按线性增加。

当拥塞发生时，就把慢开始门限ssthresh设置为出现拥塞时的发送窗口的一半（不小于2），并设置拥塞窗口为1，执行慢开始算法。

![tcp block control](http://jums.club/images/article/4454545454545.png)

快重传：快重传算法要求接收方每收到一个失序的报文段后，就立即发出重复确认，而不是等到发送数据时才进行捎带确认。同时规定发送方只要收到三个重复的确认就立即重传对方尚未收到的报文，而不是等待报文的重传计时器到期。采用快重传的算法，可以使得网络的吞吐量提高约20%。

快恢复：当发送方收到三个重复的确认，就执行“乘法减小”算法，把慢开始门限ssthresh减半，但不执行慢开始算法，而是采用拥塞避免算法，每个RTT就将拥塞窗口加1。

### nagle算法
Nagle算法主要用于预防小分组的产生。广域网中大量TCP小分组可能造成网络拥塞。Nagle算法针对每一个TCP连接，要求TCP连接最多只能有一个未被确认的小分组。在未收到确认前，TCP会收集这些小分组，然后将它们合并。收到确认或超过一定时延（带时延的ack，通常是200ms），会将这个合并报文发出去。

可以通过设置TCP_NODELAY选项来关闭Nagle算法。特别是针对telnet或ssh这种交互性强的程序。

### 访问URL全过程
* 浏览器输入URL，并按下回车
* 浏览器查找当前URL是否存在缓存，并比较缓存是否过期
* DNS解析URL对应的IP
* 根据IP建立TCP连接，三次握手
* 发起HTTP请求
* 服务器处理请求，浏览器接受HTTP响应
* 渲染页面，构建DOM树
* 关闭TCP连接，四次挥手

### DNS解析
* 先检查本地hosts文件是否有这个网址映射关系，如果有就调用这个IP地址映射，完成域名解析；
* 如果没找到则会查找本地DNS解析器缓存，如果查找到则返回；
* 如果还是没有找到则会查找本地DNS服务器，如果查找到则返回；
* 最后迭代/递归查询，按根域服务器、顶级域、第二层域、子域查找域名对应的IP地址。

### 强制缓存与对比缓存
强制缓存由cache-control和expires字段控制，expires是一个绝对时间，表示起始时间；cache-control的max-age字段指定缓存从起始时间之后的有效秒数。

对比缓存由last-modified和Etag字段判断。last-modified是第一次请求时返回的字段，后续请求时，就发送if-modified-since字段，服务端会比对两者，如果不一致则认为缓存过期，并返回最新资源；如果时间一致则发送304状态码，浏览器可以使用本地缓存。

### HTTPS
HTTPS，也称作HTTP over TLS。TLS的前身是SSL，TLS 1.0通常被标示为SSL 3.1。

HTTPS采用了加密传输，而HTTP是明文传输。前者使用443端口，后者使用80端口。

HTTPS相比HTTP，提供了，
* 数据完整性校验
* 数据隐私保护
* 身份认证

完整性和隐私性由TLS Record Protocol保证；身份认证由TLS Handshaking Protocol实现。

HTTPS加密传输前，需要先验证服务端身份，然后交换通信密钥。（单向认证，也可以双向认证）

所以，HTTPS的基本过程为，
* 客户端发起一个HTTPS请求，连入到server的443端口。发送一个随机值1和支持的加密算法。
* 服务端发送匹配的加密算法和随机数2；并发送服务器自身的证书（公钥、颁布者、有效期、数字签名等）
* 客户端TLS负责校验公钥，颁发机构，过期时间等信息，若没有问题，生成一个预主密钥，并将随机数1/2和预主密钥用服务端公钥加密，传输给服务端。
* 服务端用自己私钥解密，得到随机数1/2和预主密钥，组成得到会话密钥。
* 此后，两者通过会话密钥使用对称加密算法通信，保证数据隐私性。

这里面利用了非对称加密RSA进行密钥交换，并利用CA签名的证书保证公钥的可信的。然后利用对称加密进行数据传输，解决数据传输的效率问题。

![keygen](https://img.halfrost.com/Blog/ArticleImage/121_3_0.png)

主密钥（MasterSecret）将两个随机数和预主密钥送入随机函数PRF生成主密钥；
会话密钥（SessionKey）是两个随机数和主密钥送入PRF生成。


### 服务器链接上限
一个TCP连接由4元组（local ip, local port, remote ip, remote port）唯一标识。

不考虑地址重用（SO_REUSEADDR）的情况，即使server有多个ip，本地监听的端口也是独占的。因此server端tcp连接只有remote ip和remote port可变。可以计算除最大理论上线为：2^32次方 * 2^16次方（不考虑ip地址分类，以及本地系统保留的端口限制），即为2^48次方。

上面是理论上限，还可能受限于物理机的性能，如允许最大打开的文件描述符上线，内存限制，端口限制等。
* linux中，单个进程打开文件的最大数量，默认是1024个，可使用 ulimit -n 100000修改
* 内存限制，一个socket连接，大约占用内存为15-20kB
* 端口限制，linux中0-1023的端口是系统保留的，用户可使用1024-65535范围的端口。

### 惊群效应
多线程或者多进程中，同时阻塞等待同一个时间而处于休眠状态。当某个事件发生，将所有等待者唤醒，但最终只能有一个进程或者线程拥有资源。其他进程或者线程有再次休眠。
* 多进程
  多个进程，使用epoll_wait等待同一个文件描述符的就绪事件，最终会唤醒所有进程，但最终只有一个成功，其他进程返回EAGAIN。

* 多线程
  多线程，使用条件变量同步事件。当某个事件就绪了，使用pthread_cond_boardcast将唤醒所有等待者。

解决惊群效应的方法：加锁。nginx中多个work进程accept时，会抢占一个全局的锁，只有一个进程抢夺锁，然后调用accept，其他进程立即返回。

### SO_REUSEADDR和SO_REUSEPORT参数
* SO_REUSEPORT
  使得多进程或者多线程创建多个绑定到同一个ip：port的监听socket，提高服务器接收连接的并发能力。需要所有进程和线程设置SO_REUSEPORT才生效。（setsockopt）解决问题，
  * 避免引用层多线程或多进程监听同一个ip：port的"惊群效应"
  * 内核层面的负载均衡，保证每个线程或者进程收到均衡的连接数

* SO_REUSEADDR
  当某个socket绑定了IP：port，并处于TIME_WAIT状态，此时启动另一个socket绑定相同的IP和port，就需要使用SO_REUSEADDR参数。（如果不使用该参数，报错端口正在使用，需要等待2分钟。）
  该选项还支持同一个端口上启动同一个服务器的多个实例，他们绑定不同的ip。

