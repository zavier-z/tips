### 进程，线程，协程
* 进程
每个进程都有自己**独立的地址空间**，进程是程序运行的实体，**资源分配的最小单位**。不同进程使用IPC来通信。相比线程，进程切换代价更高，需要切换地址空间，栈和上下文寄存器组。同时，L1 cache和TLB都失效。

* 线程
线程是进程中的一个实体，是一个独立的执行流。他是linux**调度的最小单位**。在进程中的**所有子线程共享进程的资源**，包括地址空间，打开的文件描述符，信号处理函数。线程切换代价小于进程，它不需要切换页表，但是每个线程有**独立的栈**，所以栈和上下文寄存器组是要切换的。线程间通信一般通过共享内存+锁来实现。

* 协程
协程是一种**用户态轻量级线程**。每个协程有**独立的栈**，协程切换最**轻量**，不需要陷入内核，只需要保存**用户态的栈和上下文**。所以，协程可以采用**同步编码，异步调度**，遇到阻塞就切换，非常适合IO较多的场合。对于计算密集性任务不友好。

### 进程栈、线程栈、内核栈和中断栈
* 进程栈
又叫主线程栈，fork时创建，大小为2页，支持写时拷贝COW，动态扩展，最大8MB（可配置）
内存描述符mm_struct中存储了进程栈的起始地址start_stack。

* 线程栈
创建线程时，和fork一样调用clone，不过加上了CLONE_VM选项，将线程的内存描述符指向父进程的mm_struct结构。

但子线程栈mmap映射时，不使用VM_STACK_FLAGS标志，且创建的子线程和主线程共享了mm_struct结构，而mm->start_stack存储了主线程栈，因此子线程栈没有存储到mm_struct，而是存储在task_struct->thread->sp中（指向struct pt_regs对象）。

使用mmap意味着，线程栈不能动态增长，一旦用尽，导致栈溢出，出现断错误。

![mm-struct](https://img-blog.csdn.net/20160901215036575)
![memory overlay](https://img-blog.csdn.net/20160901214948512)

* 内核栈
每个进程必然会通过系统调用接口陷入内核，这时使用的栈不是用户空间的栈，而是单独的内核栈。每一个线程都对应有一个内核栈，大小为THREAD_SIZE，大小为一页（4KB）。它是通过slab分配器thread_info_cache分配的。

为方便从内核栈快速获取task_struct，内核栈的栈底存储了thread_info struct，里面包含了进程描述符task_stuct指针。这也是current宏的实现。

* 中断栈
通常中断存在多中优先级，支持嵌套，因此每个cpu都有一个中断栈，大小为2页。
但是不同体系机构，策略可能不同。ARM体系结构中断栈将使用内核栈，X86结构内核栈和中断栈是分开的。

### 多线程中堆共享
多线程中栈是独立的，但是同一个进程中的所有线程是共享同一个堆。不同进程的堆栈是不一样的。

进程的堆在**内存描述符**mm_struct中，包含了**start_brk和brk**。它们分别代表堆区的起始和结尾地址。这个结构还包括堆区的管理结构**vm_area_struct**。

但是在多线程环境，**减少堆分配的锁竞争**，会为每个线程创建私有的堆分配器。他们都有各自独立的空闲链表，管理一些空闲的堆内存块。这就是用户层堆分配器，如gnu和**ptmalloc**，google的**tcmalloc**，和facebook的**jemalloc**。

他们都是解决如何高效的进行堆分配，又不造成大量碎片，导致浪费和性能降低。这些分配策略在分配不出内存，或者分配内存块太大时，将分别调用**brk扩展堆**，和**mmap匿名映射**来分配。所以malloc/free可能额外的导致系统调用开销。

### 内核线程与用户态线程
pthread是用户空间线程库，采用的是线程-进程1对1的模型，即一个用户线程对应一个轻量级进程，而一个轻量级进程对应一个特定的内核线程。将线程的调度等同于进程的调度，这是由内核完成的。

内核线程只运行在内核态，没有独立的地址空间，且不受用户态上下文的拖累。它可以在全系统范围内竞争处理器资源，唯一使用的资源是内核栈和上下文切换时保持寄存器的空间。

大多数协程库完全建立在用户空间，用户创建，调度，同步，销毁都由用户空间库完成。用户空间创建的协程对内核空间是透明的，因此其所属线程参与处理器竞争，进程中所有线程参与该进程的资源竞争。


### 进程上下文和线程上下文
* 进程切换过程
  * 切换页目录，即**页表**，使用新的地址空间
  * 切换内核**栈**和**硬件上下文**
对于线程而言，是无需切换页目录的，但进程需要两步。

* 切换带来的性能开销
  - 线程切换没有地址空间的开销，但进程和线程切换都有寄存器组的保存和恢复
  - 切换上下文时，处理器缓存cache失效，如果切换了地址空间，那么TLB页表缓冲也全部失效，导致未来一段时间的低效执行。

* 进程上下文，当一个进程在执行时，CPU的所有寄存器中的值、进程的状态以及堆栈中的内容被称为该进程的上下文。
    * 系统调用，触发异常，属于进程上下文。

### 中断上下文
* 中断执行的上下文，不能被抢占（中断不能被挂起，转而指向其他线程任务），但允许嵌套，高优先级可以优先执行。所以也称为原子上下文。在中断上下文中，不能执行一些可能休眠的操作，因为中断上下文中是不能阻塞的。这些操作可能是，
    - **主动放弃CPU**，一旦放弃，是没有一个内核结构可以保存中断上下文的，就意味着不能被恢复了。
    - **占用互斥体**，互斥体占用失败，将导致休眠。如果要使用锁，只能使用spinlock
    - **执行耗时操作**，中断应该快速执行完毕，因为在中断处理过程中关闭了本地中断和抢占，严重影响到系统的响应时间。
    - **访问用户空间虚存**，中断是异步发生的，中断上下文和进程上下文是无关的，此时current宏是可能代表任意进程。
    - **中断处理程序是不可重入的**，也就是不支持SMP并发运行同一个中断处理实例（不支持多个CPU同时调用同一个中断处理函数）

### 软中断
软中断是一种延时机制，代码执行的优先级比进程要高，比硬中断要低。相比于硬件中断，软中断是在开中断的环境中执行的（长时间关中断对系统的开销太大）。通常要求中断上半部要快速处理，一些耗时操作，在中断中调用raise_softirq来触发软中断来推迟执行。

在中断退出irq_exit时，会调用invoke_softirq处理软中断。同时在SMP架构中，每个cpu都会创建一个内核线程ksoftirqd来处理软中断事件，这些内核线程在没有任务时休眠。所以在执行invoke_softirq时，会调用wakeup_softirq唤醒内核线程，执行do_softirq来处理软中断。（10次softirq_vec[i]->action，然后触发线程）

尽管，软中断在开中断下运行，可被其他高优先级中断打断（保证实时性），但是在执行do_softirq时关闭了本个CPU的中断下半部（Bottom-half），具体通过__local_bh_disable和__local_bh_enable来开关下半部。所以通类型的软中断是不允许嵌套的，只能在一个CPU上串行执行，但多个CPU可以执行不同类型的软中断。（timer，tasklet）

### 进程间通信
常见的进程间通信方法有，
* 管道
  - 匿名管道
    - 一种半双工，数据只能单向流动，且只能有亲缘关系的进程的通信方式
  - 命名管道
    - 一种半双工，但允许非亲缘进程之间通信。
  
* 消息队列
  - 消息队列是由消息组成的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
 
* 共享内存
  - 共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的IPC方式。但数据访问需要配合其他同步互斥方法。

* 信号量
  * 信号量是一个计数器，可以用来控制多个进程对共享资源的访问(计数信号量和二值信号量)。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

* 信号
  * 用户通知进程，可以是其他进程，也可以是自身，某个事件发生了。

* socket
  * 套接字也是一种进程间通信机制，可以跨主机进程通信。

### 信号
信号在软件层对中断的一种模拟，是一种异步的通信。linux提供了几十种的信号。
进程收到信号，一般处理方法有三种，
* 执行默认操作，SIG_DFL
* 捕捉信号，执行自定义信号处理函数
* 忽略信号，SIG_IGN

但是SIGKILL和SIGSTOP信号不能捕捉，这是为了能强制让某个进程中断和结束。

linux常见的信号，
* SIGKILL
* SIGSTOP
* SIGINT，ctrl+c触发该信号
* SIGCHLD，子进程退出时，向父进程发送此信号
* SIGTSTP，ctrl+z触发该信号，挂起进程(fg恢复到前台运行，bg恢复后台暂停任务继续执行，jobs查看后台任务，nohup不挂断执行)
* SIGALARM，定时器溢出时，调用alarm向某个进程发送此信号

常用信号API，
* raise，向自身发送信号
* signal和sigaction，绑定信号的处理函数
* kill，向任意进程发送信号

### 管道
* 匿名管道
  * 通常，双向通信时需要建立两个管道。它是一种内核缓冲区，一种循环队列结构，存在于内存的文件。维持了一对读写指针，所以读走的数据，不能重复读，是流数据。使用pipe创建匿名管道，通常配合fork使用。当父子进程都不引用管道时，此结构自动释放。当队列为满时，阻塞写，当队列为空时，阻塞读。

* 命名管道
  * 在磁盘上有对应的inode，但是没有数据块。可以使用mkfifo创建命令管道，在文件系统中有对应的文件名。只要有权访问这个文件的两个进程，就可以通过读写这个文件实现通信。当进程关闭命名管道时，管道并不会消失，除非删除。

多个进程同时写管道，数据会混在一次，无法辨认，没有消息边界。

pipe管道是一种特殊的文件，可以调用write和read。它只出现在内存中，没有名称，没有inode，没有数据块。

* shell管道实现
在shell中，很常见一个命令的输出作为另一个命令的输入，如cat file ｜ wc -l，用来统计文件的行数。

这就是将前一个的命令标准输出重定向到第二个命令的标准输入，其实就是利用复制文件描述符dup2。

pipe生成两个文件描述符。fd[0]输出，fd[1]输入。

那么对于前一个进程以STDOUT_FILENO复制到fd[0]上，后一个进程以STDIN_FILENO复制到fd[1]上。这样fd[0]就引用了第一个进程的标准输出，fd[1]就引用了第二个进程的标准输入，就能进行进程间通信了。

* popen实现
是对pipe和fork的一层封装。创建了一个管道，并创建子进程来完成shell命令，然后通过读写管道传递输入参数，或执行结果。

### 消息队列
消息队列，就是一个消息的链表结构，用户写记录时可以挂消息在链表中，读数据时从链表中取出一个节点。

消息队列与管道通信相比，其优势是对每个消息指定特定的消息类型，接收的时候不需要按照队列次序，而是可以根据自定义条件接收特定类型的消息。可以把消息看做一个记录，具有特定的格式以及特定的优先级。

常用函数API，
* system v
  * ftok，根据输入字符串生成唯一的ID，作为key
  * msgget，创建并打开消息队列，qid=msgget(key, IPC_CREAT|0666)
  * msgsnd，发送消息，**需要指定消息类型**
  * msgrcv，接受消息，**可以指定接受消息的类型，为0表示接受任意类型数据**
  * msgctl，控制消息队列，msgctl(qid, IPC_RMID)
  
* posix，根据优先级输出消息，高优先级优先输出。
  - mq_open、mq_close
  - mq_unlink
  - mq_send、mq_receive
  - mq_setattr、mq_getattr

### 共享内存
共享内存进行通信的一个主要好处是**效率高**，可以**避免多次内存拷贝**。
共享内存允许两个或多个进程共享一个给定的存储区，这一段存储区可以被两个或两个以上的进程映射至自身的地址空间中。建立好共享页面后，多个进程可以**通过指针读写共享内存**。但共享内存并没有提供各同步方法，所以一般需要和同步方法联合起来使用。

一般如管道或消息队列进行进程间通信时，需要4次拷贝，
* 写入过程：用户空间到内核缓冲；内核缓冲到管道或消息队列内部数据结构；
* 读出过程：内核数据结构拷贝到内核缓冲区；内核缓冲区拷贝到用户空间；

使用共享内存，一般需要2次拷贝，共享内存读写操作不再是系统调用，所以不需要进过内核缓冲区中转一次。
* 写操作，直接写被映射的共享内存，一次拷贝；
* 读操作，直接读被映射的共享内存，一次拷贝；

共享内存实现方法，
* 内存映射，posix
    * 使进程之间通过映射同一个普通文件实现共享内存，通过mmap()系统调用实现。普通文件被映射到进程地址空间后，进程可以像访问普通内存一样对文件进行访问，不必再调用read/write等文件操作函数。

* 共享内存，system v
    * 共享内存是通过映射特殊文件系统shm中的文件实现进程间的共享内存通信。
    * system v把所有的共享数据放在共享内存区，任何想要访问该数据的进程都必须在本进程的地址空间新增一块内存区域，用来映射存放共享数据的物理内存页面。
    * 所以每个共享的内存区域，有唯一标识id，可以通过ftok生成，然后通过shmat建立映射，并返回读写指针。最后使用shmdt解除映射关系。

### 多线程的同步与互斥
* 互斥量mutex
* 条件变量
* 读写锁

### 可重入、线程安全和异步信号安全
* 线程安全
    * 线程安全强调的是一个对象或者函数，在多线程并发访问时，不会出现共享资源访问出错问题。
    * 常见的线程安全的方案，
        * 私有化对象，保证访问对象是对线程私有的，那么就不会出现共享资源并发写造成冲突。
        * 对于一定要共享的对象，加锁串行访问。
        * 整型值，可以使用原子类操作，如CAS，load，store等。

* 可重入与异步信号安全
    * 可重入和异步信号安全是同一个概念。他们强调函数在访问过程中可以被打断，后续可以恢复执行不会出错。这要求函数内部不依赖全局变量，局部静态变量，以及不能调用非重入得函数，如malloc，io函数。

即使对共享资源加锁，让其变成线程安全，但仍然不构成异步信号安全的条件。异步信号安全，可能在访问锁后，被打断，并在信号处理函数中调用同一个函数，再次获取锁，导致死锁。

### 任务调度策略
任务分为实时进程和普通进程，实时进程总是优先普通进程执行。
调度策略分为，
* 分时调度策略SCHED_OTHER（默认，也称为SCHED_NORMAL）
* 实时调度策略，
  - SCHED_FIFO，先到先服务，一旦运行，除非自己放弃，否则一直运行。
  - SCHED_RR，时间片轮转，实时进程优先调度

对于实时进程，只有静态优先级，内核不会根据睡眠等因素对静态优先级作调整，范围为0～MAX_RT_PRIO-1之间，默认MAX_RT_PRIO为100。
而，nice值影响MAX_RT_PRIO～MAX_RT_PRIO+40范围内的进程（100-139）。nice值范围为-20～19，值越小优先级越高。

可以通过nice或者renice命令来调整进程的动态优先级。

* 普通进程与实时进程
    * 实时进程一旦就绪，总是抢占普通进程；
    * FIFO调度，一直运行到主动放弃CPU或有更高优先级任务就绪为止；没有时间片的概念；
    * RR调度，为每个相同优先级任务分配相同时间片，轮流执行；如果当前实时任务时间片耗尽，没有同级或更高优先级实时任务，则继续执行。

普通进程按照动态优先级调度，而动态优先级是由静态优先级static_prio调整而来。两者关系为dynamic_prio = MAX_RT_PRIO+nice+20。
所以，静态优先级范围为100～139，nice值越大static_prio越大，最终进程优先级就越低。

linux2.6之后考虑到交互式进程应该赋予更多调度的机会，通过监控进程的睡眠时间，对于睡眠时间越多的任务给予bonus，值为0～10，用于生成动态优先级。交互式IO进程可以获得更多调度的机会，而计算密集型进程调度可以迟缓一点，但是运行时间要长，中途最好不被打断。
但是bonus只影响普通进程，对实时进程无效。dynamic_prio = max(100, min(dynamic_prio_prev - bonus + 5, 139))

### 任务调度状态机
* TASK_RUNNING
  进程处于就绪态，或者处于执行态

* TASK_INTERRUPTIABLE
  可中断睡眠状态，可能在等待时间，如信号量或者互斥锁

* TASK_UNINTERRUPTIABLE
  不可中断睡眠状态，不响应异步信号，包括SIGKILL。在使用vfork时，子进程运行期间，父进程处于此状态。另外，在fork时，在未设置好task_struct时，也设置为此状态。

* TASK_STOP和TASK_TRACE
  TASK_STOP表示暂停状态，当进程收到SIGSTOP信号时，被设置为此状态。当重新收到SIGCONT信号时，恢复TASK_RUNNING状态。
  TASK_TRACE表示跟踪状态，被跟踪进程处于暂停状态，当接收到PTRACE_CONT和PTRACE_DETACH时恢复为TASK_RUNNING。

* TASK_DEAD
  - EXIT_ZOMBIE
    处于TASK_ZOMBIE状态进程称为僵尸进程，此时进程除了task_struct结构外，其他所有资源都被回收。此时task_struct结构中保留着进程退出码和一些统计信息。在进程退出过程中，内核会向父进程发送SIGCHLD信号。父进程调用wait系统调用获取子进程退出信息，然后子进程被完全释放。如果，父进程先于子进程死亡，那么子进程先在同进程组中找一个进程为父进程，如果没有，就选择init进程。init进程会清理所有的僵尸进程，回收资源。

  - EXIT_DEAD
    进程即将被销毁。


![task automaton](https://images0.cnblogs.com/i/401155/201404/201153238078305.jpg)


### 内核抢占
在linux2.4时，内核不支持抢占。高优先级任务就绪时，只能等低优先级返回用户态时，才触发调度。（实时性差一点）

在linux2.6时，内核支持抢占。但在临界区时也需要设置为禁止抢占。如spin_lock，持有自旋锁时不能被抢占，否则锁没有释放情况下被抢占，可能导致死锁。

### 多处理器下的负载均衡
单运行队列，无需考虑多处理器的负载均衡，但是全局的运行队列，需要加锁访问，所以性能有所下降。所以引出了每个CPU都有一个私有运行队列。带来的好处是，无需加锁，另外，同一个进程在一段时间内总是在同一个CPU上运行，很可能CPU的各级cache都保留着，有利于系统性能提升。

多运行队列，就需要使用策略让各个CPU负载保持相当。同时调整的频率还不能太高，否则加锁，任务迁移也会带来性能损失。

### 优先级继承解决优先级反转
优先级反转：一个非常低的优先级任务A先进入临界区，此时高优先级任务B处于就绪状态，另外一个中等优先级C抢占了A执行，导致高优先级B反而等待低优先级C执行。

优先级继承：当低优先级任务A先于高优先级任务B进入临界区时，临时提高低优先级任务A到B的优先级，保证执行期间不被低优先级打断，可以快速执行，退出临界区时恢复优先级。

### 完全公平调度CFS
为每个进程安排了一个虚拟时钟vruntime，如果进程正处于执行，这个值随时间增长而增长，没有得到执行vruntime保持不变。
调度器总是选择当前vruntime最小的进程执行，这就是完全公平的由来。

但任务有优先级，高优先级就是需要更多的时间片和优先执行。为了保持公平性，只能让高优先级进程vruntime增长得更慢，它就能获得更多运行的机会。（这可以保证高优先级可以有更多机会获取CPU，且能运行更长的时间片）

分配给进程的时间片 = 调度周期*(进程权重/权重和)。调度周期为将所有处于TASK_RUNNING进程调度一遍所需时长。
vruntime = 实际运行时间*(1024/进程权重) = 调度周期 * 1024 / 进程总权重。
所以vruntime的推进速度和权重无关的。进程的权重和nice值有一一对应关系。nice值越大，权重越低。

linux将所有处于TASK_RUNNING状态的进程，以vruntime（vruntime-min_vruntime）插入红黑树，并缓存最左侧节点，就可以快速选中vruntime的进程。


### 伙伴算法
buddy子系统用于解决频繁请求和释放不同大小的一组页框，造成的外部碎片问题。即使有足够的页框可以满足请求，但无法分配连续的大块的页框。

伙伴算法把空闲页框分为11个块链表free_area，他们按照2的次幂大小管理页框，比如，第0个块链表包含2^0个连续页框，第一个块链表，包含2个页框大小的连续地址空间，依次类推。所以伙伴算法只能按照2的次幂分配页空间，从1页到1024页，所以最多一次分配4M的内存。

linux2.6为每个管理区zone使用不同的伙伴系统，内核的分区主要分为3种，DMA，NORMAL和HIGHMEM，每一种都对应一个伙伴系统。

相同大小内存块，地址连续，属于伙伴。如，第0块和第1块是伙伴，第2块和第2块是伙伴（但第1块和第2块不是伙伴）。用位图状态码表示伙伴是否被分配。

* 申请块流程，如分配4页的内存，
    * 首先去free_area[2]找是否有空闲块，有就直接分配。如果没有就去上一级free_area[3]找，找到了就分配，并把多余的页框加入到free_area[2]中。
    * 如果到free_area[10]都没有找到空闲块，报告分配失败。

* 释放块流程
    * 释放时，先在free_area链表中找伙伴，如果没有，就插入对应页大小的链表头。如果有，就合并，然后下一级链表中继续查找合并，直到不能合并为止。

* 伙伴算法优缺点
    * 优点
      * 较好解决外部碎片问题
      * 能尽力分配出连续的页框，用于一些DMA操作
      * 只要块不超过4M，伙伴算法都能很好的工作。（超过4MB，就mmap映射）
  
    * 缺点
      * 合并要求过于严格，只有满足伙伴关系的块才能合并。如第1块和第2块是不能合并的。
      * 碎片问题，一个连续页只要有一个页被占用，整块内存页都不能合并。
      * 浪费问题，伙伴算法只能分配2的次幂内存块，如果申请9KB，就只能分配16KB，这会浪费剩余的7KB。
      * 效率问题，内存块释放时，总是会查找伙伴并合并。如果刚合并好插入上一级链表，此时又不足以分配新的内存块，又不得不拆掉刚合并的内存块。（无效合并）

### slab
* 外部碎片
由于分配页时是离散的，可能导致分配大的连续页框失败。这些按页空闲空间称为外部碎片，只能用于分配小块内存。

* 内部碎片
内核一般按页分配，当我们申请几十个字节，也是如此。这样每个页造成了很大浪费。这称为内部碎片。

slab分配器是基于对象管理，对象可能是内核中需要频繁创建销毁的数据结构，如task_struct，file_struct，inode等。
相同类型的对象归为一类，每当要申请这样一个对象时，slab分配器就从一个slab列表中分配一个这样大小的单元出去，而当要释放时，将其重新保存在该列表中，而不是直接返回给伙伴系统，从而避免内部碎片。
slab分配对象时，会使用最近释放的对象的内存块，因此其驻留在cpu高速缓存中的概率会大大提高。

![slab](https://images2015.cnblogs.com/blog/739465/201511/739465-20151119134831811-1294977243.png)

一个kmem_cache结构描述了一个高速slab对象缓存。所有的kmem_cache构成一个链表cache_chain。

一个kmem_cache又有三个链表，对应3种slab：slabs_full(完全分配的slab)，slabs_partial(部分分配的slab)，slabs_empty(空slab，或者没有对象被分配)。

slab是slab分配器的最小单位，在实现上一个slab有一个或多个连续的物理页组成（通常只有一页）。
单个slab可以在slab链表之间移动，如如果一个半满slab被分配对象后变满了，就要从slabs_partial中被删除，同时插入到slabs_full中去。

如，要从inode_cachep的struct kmem_cache节点中分配inode对象，
* 首先在inode_cachep的slabs_partial中选中一个slab，分配一个对象，如果slab满了就挂入slabs_full链表中；
* 如果，slabs_partial为空，就去slabs_empty中寻找，如果找到了，分配一个对象，然后将该slabs挂入partial链表；
* 如果slabs_empty也为空，那么只能新建slab了。

### TLB与Cache
TLB：Translation Lookaside Buffer，地址转换缓冲器，又称快表。它将缓存mmu转换后的虚拟页号与物理页号，由于局部性原理，这些被缓存的页近期有很大可能再次被访问。缓存了转换结果后，省掉mmu再次查页表的过程。

mmu：memory management unit，内存管理单元。它用于将虚拟地址转为物理地址，以及分区保护。它是内核和用户层隔离，进程间地址空间隔离与共享的主要器件。（地址转换和分区保护）

page table：用于将虚拟地址转为物理地址。虚拟地址一般被分为很多段，以对应不同的页表索引。mmu中会存储页表的基地址，此后在转换地址时，就通过各级页表索引进行转换。将虚拟页号转为物理页号。
如linux当下支持最大5级页表，即pgd、p4d、pud、pmd、pte。32位 x86系统中通常使用两级页表：pgd页全局目录[31：22]和pte页表[21：12]，64位x64系统采用4级页表：pgd、pud（页上级目录）、pmd（页中间目录）和pte。

cache：一般分为指令cache、数据cache和混合cache。它将内存中的指令或数据缓存起来。由于cache是高速缓存，相比内存速度又快许多，所以这加快了CPU取指和访存的速度。

![memory access](http://blog.chinaunix.net/attachment/201206/24/26732852_1340551331PtZF.png)

* 多级页表的优劣
多级页表实质上是增加了索引数。

可以离散存储页表。如4GB地址空间，每页为4KB，则需要2^20个页表项将所有地址覆盖，每个页表项占用4B，所以共需要连续4M空间。对于一些内存紧张的场景，不太适合分配大的连续空间。如果使用多级页表，那么每级页表是可以分配存储的。

可以节约页表内存。刚刚4GB地址空间，需要4MB来存储一级页表。如果一个进程只需要访问4M，也是需要4MB页表。如果是二级页表，如果二级页表索引占10bit，那么映射4MB只需要另外4k存储一级页表，就可以覆盖进程使用的4MB空间。所以对于只使用一级页表需要4M+4M=8M，使用二级页表需要4KB+4M内存。

使用多级页表带来的弊端是，增加寻指次数，延长访存时间。

### 流水线
流水线实现了多条指令的并发执行。
流水线越细，理论上效率越高，但是指令跳转、排空流水线造成的性能开销越大。

### 分页与分段
* 物理地址：对应物理内存的地址
* 线性地址/虚拟地址：在有MMU的系统中，CPU访问的地址
* 逻辑地址：Intel为了兼容段式管理，将地址分为段基地址，和段偏移。两者组装起来称为逻辑地址；

Intel中首先根据段式管理，将段基地址和段偏移组装称为线性地址，然后根据页式管理，将线性地址转换为物理地址。

分页是一维的，只需要给虚拟地址，就可以根据页号在页表中查询对应的页框，然后根据页偏移找到对应的物理地址。

分段是二维的，将逻辑空间划分为不同的段，如数据段，堆栈段，代码段等，每个段的大小也是不固定的。
在访问段时，需要指定段寄存器，用来找到对应的段基址，然后根据段偏移找到逻辑地址。

### 虚拟文件系统
* 层次结构
    * VFS：提供一个统一的文件系统访问的抽象接口，便于扩展，保持上层应用接口不变。
    * NFS，EXT2，NTFS等是具体文件系统实现细节。它需要实现VFS定义的接口
    * page cache：文件系统的块高速缓存。每次读写磁盘时，首先访问页缓存。提高读写的性能，但可能导致数据不能及时写入磁盘，持久化。
    * 通用块层：负责维持一个I/O请求在上层文件系统与底层物理磁盘之间的关系，通常使用一个struct bio结构来表示一个I/O请求。一个I/O请求可能对应多个页得读写，所以bio的scatter I/O更加高效。
    * I/O调度层：磁盘的寻道时间是很慢的，毫秒级别。所以需要对上层的读写请求进行合并和排序，减少寻道时间，通常使用电梯算法。
    * 块驱动层：负责块设备读写的操作。
![layout](https://upload-images.jianshu.io/upload_images/6762069-70502bfd115cda2c.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

* 核心数据结构
    * super_block
    * inode
    * dentry
    * file

* super_block
超级块用于存储文件系统的元信息，主要包括文件系统类型、大小、区块数，挂载点，索引dentry和操作方法super_operation。

主要的操作包括创建、删除、读写inode方法，以及更新、释放、锁定超级块的方法。

* inode
索引节点包含文件的元数据，如文件权限、字节数、所属组id号、拥有者id号、时间戳和引用数等，但就是不会包括文件名。文件名在目录的目录项中存在，与inode有对应关系。

主要操作包括inode创建，软链接，硬链接，目录创建、删除等常规的文件操作。

* dentry
路径中每一部分都看作是dentry对象，如/bin/ls，bin属于目录文件，ls是普通文件，他们都用inode对象表示。
VFS为了方便查找操作，将“/”，“bin”，“ls”都看作是目录项对象。

目录项不存在磁盘中，VFS根据字符串形式路径在内存动态创建。它的的存在，是便于VFS作路径查找。为了加速查找过程，VFS还是用了目录项缓存dcache，并使用hashtable缓存最近解析过的路径的目录项。方便在下次需要解析路径时，使用d_hash函数计算哈希值，快速在hashtable中找到匹配项。因为文件访问空间和时间的局部性，对目录项的缓存命中率概率较高。

页目录项操作方法dentry_operations主要有：比较文件名、哈希方法、删除与释放等。

* file
文件对象表示进程中已打开的文件，是已打开文件在内存中的表示。在使用open时被创建，在调用close时撤销。同时，多个进程可能同时打开同一个文件，所以同一个文件可能包含多个文件对象，但他们对应的dentry和inode对象是唯一的。

文件对象和dentry对象一样，是在内存中创建，没有对应的磁盘数据，所以不需要脏标志来判读是否需要写回磁盘。脏标志存在于inode中，可以通过f_path找到dentry，然后在找到对应inode结构。

file_operations包含了常见文件操作的方法。

![core stucts relationship](https://upload-images.jianshu.io/upload_images/6762069-3d10b97eb9750b02.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)


### 块设备
linux支持不同存储介质，所以每种块设备硬件在内核空间都适配有驱动程序，来读写块设备。往上是IO调度层，将文件系统的读写请求排序，合并用以提高磁盘读写效率。接着是，通用块层，对应于bio结构，它将一次IO请求进行抽象，描述对应IO操作涉及到的多个页，他们可以是地址不连续的。文章主要是对IO调度层涉及到的调度算法和重要的结构体作介绍。

目前，内核中块IO操作的基本容器由bio结构体表示，它以片段链表形式来组织块IO操作。一个片段可以是一小段连续的内存缓冲区，这样bio结构就可以描述一个分散在多个内存位置的缓冲区，这样的块IO操作称作scatter IO。

块设备的I/O请求是放入一个request_queue的队列中，其中每一项都表示一个单独的请求，由request结构表示。由于每个I/O请求可能涉及到多个页面，所以有bio结构来描述I/O涉及到的多个片段。

具体而言，bio结构中包含bio_vec数组，它是指向一个物理页中连续的地址空间，包括页、页偏移以及大小。而bio_vcnt表明了bio_io_vec数组大小，bi_idx表明了当前指向那个页面。所以，bio_vec结构指明了一个IO操作所使用的所有片段。

IO调度器的工作就是管理块设备的请求队列。由于磁盘最慢的操作是寻道，所以IO调度器大部分工作是合并和排序，以提高磁盘的吞吐率。通过合并减少IO请求的次数，通过排序减少随机访问带来的寻道开销。
  
在linux中支持5种IO调度算法：linus电梯算法、最终期限IO调度算法、预测IO调度算法、完全公正IO调度算法和空操作IO调度算法。默认，linux 2.6内核使用预测IO调度算法。
![block dev](https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fwww.spasvo.com%2Fckfinder%2Fuserfiles%2Fimages%2F2016062041380652.png&refer=http%3A%2F%2Fwww.spasvo.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1648522101&t=779cee886387b487d9142555b4105b0d)


### 页面置换算法
* FIFO，没有考虑局部性
* LRU，最近最久未使用，时间概念
* LFU，最不常用页面置换法，计数概念

### 僵尸进程与孤儿进程
僵尸进程：一个子进程在父进程还没有调用wait方法情况下退出，这个子进程就是僵尸进程；父进程不回收，子进程资源一致被占用。所以僵尸进程导致资源浪费。

孤儿进程：一个父进程退出，它的一个或多个子进程还在运行，子进程将成为孤儿进程，最后将被init进程收养。


### ELF PLT与GOT
GOT：global offset table，全局偏移表，动态库解析后，将这些地址保存在GOT中，有几个动态库函数，GOT就应该有多少条目

PLT：procedure link table，程序链接表。编译器发现调用动态链接库函数时，无法确定运行时地址，此时使用plt进行间接跳转。

PLT表项中，首先跳到GOT，如果这个符号已经被解析过，那么GOT已经缓存了解析结果。
如果是第一次解析，GOT表项还没有被填充，此时存储的是刚PLT跳转语句的下一条指令地址，所以又回到PLT继续执行。
此时会push一个偏移地址offset，它决定解析哪一个符号以及写入GOT那个表项，然后进入跳转到PLT[0]执行，填充GOT表项。
PLT[0]是dl_runtime_resolve，一个公共的符号解析和重定位入口。

